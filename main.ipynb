{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "4520c249d020326377e25a2d796d9ef177b60f0be4584bd4cf88763e04893382"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Capstone Project: search for a location"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1.1 A description of the problem and a discussion of the background"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We want to open one coffee shop at 3 locations--Toronto (Canada), Chicago (US), Houston (US), and New York City (USA). All those three cities within the 2 to 3 million population range, except NYC--which is above 8 million. We want to find location options for one coffee shop in each city. We would like to open our coffee shop in the established coffee-lovers area with strong human traffic. Our approach isn't the optimal solution, however, it can be useful to get yourself familiar with potential areas for our business project. Also, the obtained data can be an optional backing base among others as data-driven support for protentional investors. If our data does not line up with expert's opinions on where to start our new coffee shop we could use our data as a good point to question any reals state expert recommendation. It is good to know what kind of data an expert has to make our data look less relevant.\n",
    "\n",
    "Overall, the data from our project can be a starting point to find a local real state expert in the recommended areas.\n",
    "\n",
    "Many companies are practicing remote \"office\" when workers stay and work from home. Due to decried demand for coffee at regular office locations, we can assume that that demand is redistributed among living areas--near staying at-home workers. Out model suppose to spot this \"new normal\". If so, that would be a good checking point for our model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1.2 Description of the data and how it will be used to solve the problem"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We would like to use the city's postal codes to scan for the most trending venues. Each postal code will help to split each city into parts, it is a good base for mapping and scanning for potential target--a good spot for a coffee shop. \n",
    "\n",
    "The postal codes can be obtained over the Internet. Geolocation of those ZIP codes can be sourced over the Geocoder Python module. Then those ZIP code coordinates can be used to obtain trending venues over Foursquare API. All the trending venues will be clustered. For clustering, we will use the DBSCAN clustering algorithm. We will look for clusters with trending Coffee Shop venues. Those clusters will be mapped with the Python Folium module. \n",
    "\t\n",
    "> Python modules:\n",
    "- numpy\n",
    "- pandas\n",
    "- folium\n",
    "- geocoder\n",
    "- foursquare\n",
    "- sklearn\n",
    "- matplotlib\n",
    "\t\n",
    "\n",
    "\t\n",
    "> Postal Codes Sources:\n",
    "- Toronto Postal Codes: https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\n",
    "- Chicago ZIP Codes: https://data.cityofchicago.org/Facilities-Geographic-Boundaries/Chicago-Zip-Code-and-Neighborhood-Map/mapn-ahfc\n",
    "- Houston: https://web.har.com/zipcode'\n",
    "- New York City: https://www.nycbynatives.com/nyc_info/new_york_city_zip_codes.php\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2. Segmenting and Clustering Neighborhoods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "> In this project, I will go over a detailed explanation of every step for the city of Toronto. For Chicago, Houston and NYC all the steps explained in the Toronto case are absolutely identical. For more compact code I will remove all the narration lines from all the cities except Toronto.\n",
    "\n",
    "> All the needed tables with postal codes were preprocessed and saved into \"CSV\" files. The original sources of all the needed postal codes are listed in section one.\n",
    "\n",
    "> All the needed tables with postal codes were preprocessed and saved into \"CSV\" files. The original sources of all the needed postal codes are listed in section one.\n",
    "\n",
    "> Most of the variables will have las prefix, which is indicating to which city it belongs to:\n",
    "- _t -- Toronto\n",
    "- _h -- Houston\n",
    "- _c -- Chicago\n",
    "- _n -- NYC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my python version is 3.8.6, 64-bit on Windows 10 Home\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "source": [
    "> Loading postal codes for Toronto, Chicago, Houston, and NYC."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Postal Code\n",
       "0         M1A\n",
       "1         M1B\n",
       "2         M1C\n",
       "3         M1E\n",
       "4         M1G"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Postal Code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M1A</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M1B</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M1C</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M1E</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M1G</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "df_raw_t = pd.read_csv('https://www.dropbox.com/s/a1dawm3tgt1sgzv/toronto_zip.csv?dl=1')    # Toronto\n",
    "df_raw_c = pd.read_csv('https://www.dropbox.com/s/ssq2szny9bldl4k/chicago_zip.csv?dl=1')    # Chicago\n",
    "df_raw_h = pd.read_csv('https://www.dropbox.com/s/ff3y8odixiypg6v/houston_zip.csv?dl=1')    # Houston\n",
    "df_raw_n = pd.read_csv('https://www.dropbox.com/s/rb9wt2tfkzsyo4s/nyc_zip.csv?dl=1')        # NYC\n",
    "df_raw_t.head()"
   ]
  },
  {
   "source": [
    "> I picked \"ArcGIS\" provider for GeoCoder module.\n",
    ">>  https://geocoder.readthedocs.io/providers/ArcGIS.html\n",
    "\n",
    ">It takes a postal code and returns its latitude and longitude.\n",
    "\n",
    "> Here we iterate over all the postal codes and append received coordinates into the dictionary. Then turn that dictionary into a DataFrame and append it to the Data Frame with postal codes so we have one table with postal codes and its geo coordinates."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geocoder\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "source": [
    "> First, let's get the geo-location for each city."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Toronto is located at (43.65, -79.39)\n",
      "Chicago is located at (41.88, -87.63)\n",
      "Houston is located at (29.76, -95.37)\n",
      "New York City is located at (40.71, -74.01)\n"
     ]
    }
   ],
   "source": [
    "# coordinates of >>Toronto, Canada<<\n",
    "g_t = geocoder.arcgis('Toronto Canada')\n",
    "t_lat = g_t.json['lat']\n",
    "t_lng = g_t.json['lng']\n",
    "print(f'Toronto is located at ({t_lat:.2f}, {t_lng:.2f})')\n",
    "# coordinates of >>Chicago, USA<<<\n",
    "g_c = geocoder.arcgis('Chicago USA')\n",
    "c_lat = g_c.json['lat']\n",
    "c_lng = g_c.json['lng']\n",
    "print(f'Chicago is located at ({c_lat:.2f}, {c_lng:.2f})')\n",
    "# coordinates of >>Houston, USA<<<\n",
    "g_h = geocoder.arcgis('Houston USA')\n",
    "h_lat = g_h.json['lat']\n",
    "h_lng = g_h.json['lng']\n",
    "print(f'Houston is located at ({h_lat:.2f}, {h_lng:.2f})')\n",
    "# coordinates of >>NYC, USA<<<\n",
    "g_n = geocoder.arcgis('New York City USA')\n",
    "n_lat = g_n.json['lat']\n",
    "n_lng = g_n.json['lng']\n",
    "print(f'New York City is located at ({n_lat:.2f}, {n_lng:.2f})')"
   ]
  },
  {
   "source": [
    "> Takes each postal code and get its geo-coordinate. We do it for each city. Time consuming code execution."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>Toronto<<\n",
    "coordinates_dict_t = {}\n",
    "postal_codes_t = df_raw_t['Postal Code'].to_numpy()\n",
    "for code in postal_codes_t :\n",
    "    g_t = geocoder.arcgis(f'{code} Toronto')\n",
    "    coordinates_dict_t[code] = (g_t.json['lat'], g_t.json['lng'])\n",
    "# >>Chicago<<\n",
    "coordinates_dict_c = {}\n",
    "postal_codes_c = df_raw_c['ZIP'].to_numpy()\n",
    "for code in postal_codes_c :\n",
    "    g_c = geocoder.arcgis(f'{code} Chicago')\n",
    "    coordinates_dict_c[code] = (g_c.json['lat'], g_c.json['lng'])\n",
    "# >>Houston<<\n",
    "coordinates_dict_h = {}\n",
    "postal_codes_h = df_raw_h['ZIP'].to_numpy()\n",
    "for code in postal_codes_h :\n",
    "    g_h = geocoder.arcgis(f'{code} Houston')\n",
    "    coordinates_dict_h[code] = (g_h.json['lat'], g_h.json['lng'])\n",
    "# >>New Yourk City<<\n",
    "coordinates_dict_n = {}\n",
    "postal_codes_n = df_raw_n['ZIP'].to_numpy()\n",
    "for code in postal_codes_n :\n",
    "    g_n = geocoder.arcgis(f'{code} New York Cit')\n",
    "    coordinates_dict_n[code] = (g_n.json['lat'], g_n.json['lng'])"
   ]
  },
  {
   "source": [
    "> Turn dictionary with postal codes geo-coordinates into Data Frame."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Postal Code  Latitude  Longitude\n",
       "0         M1A  43.64869  -79.38544\n",
       "1         M1B  43.81139  -79.19662\n",
       "2         M1C  43.78574  -79.15875\n",
       "3         M1E  43.76575  -79.17470\n",
       "4         M1G  43.76812  -79.21761"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Postal Code</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M1A</td>\n      <td>43.64869</td>\n      <td>-79.38544</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M1B</td>\n      <td>43.81139</td>\n      <td>-79.19662</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M1C</td>\n      <td>43.78574</td>\n      <td>-79.15875</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M1E</td>\n      <td>43.76575</td>\n      <td>-79.17470</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M1G</td>\n      <td>43.76812</td>\n      <td>-79.21761</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# >>Toronto<<\n",
    "fd_coordinates_t = pd.DataFrame.from_dict(coordinates_dict_t, orient='index', dtype='float')\n",
    "fd_coordinates_t.rename(columns={0:'Latitude', 1:'Longitude'}, inplace=True)\n",
    "fd_coordinates_t.reset_index(inplace = True)\n",
    "fd_coordinates_t.rename(columns={'index':'Postal Code'}, inplace=True)\n",
    "# >>Chicago<<\n",
    "fd_coordinates_c = pd.DataFrame.from_dict(coordinates_dict_c, orient='index', dtype='float')\n",
    "fd_coordinates_c.rename(columns={0:'Latitude', 1:'Longitude'}, inplace=True)\n",
    "fd_coordinates_c.reset_index(inplace = True)\n",
    "fd_coordinates_c.rename(columns={'index':'Postal Code'}, inplace=True)\n",
    "# >>Houston<<\n",
    "fd_coordinates_h = pd.DataFrame.from_dict(coordinates_dict_h, orient='index', dtype='float')\n",
    "fd_coordinates_h.rename(columns={0:'Latitude', 1:'Longitude'}, inplace=True)\n",
    "fd_coordinates_h.reset_index(inplace = True)\n",
    "fd_coordinates_h.rename(columns={'index':'Postal Code'}, inplace=True)\n",
    "# >>New Yourk City<<\n",
    "fd_coordinates_n = pd.DataFrame.from_dict(coordinates_dict_n, orient='index', dtype='float')\n",
    "fd_coordinates_n.rename(columns={0:'Latitude', 1:'Longitude'}, inplace=True)\n",
    "fd_coordinates_n.reset_index(inplace = True)\n",
    "fd_coordinates_n.rename(columns={'index':'Postal Code'}, inplace=True)\n",
    "\n",
    "fd_coordinates_t.head()"
   ]
  },
  {
   "source": [
    "### 2.2 Map Toronto Postal Codes\n",
    "\n",
    ">Lets map all the Toronto's postal codes with Folium module. This part is not that important so I would like to show how it works with Toronto postal codes only.\n",
    "\n",
    "> Folium module takes all the neighbourhood coordinates and maps them on the Toronto map."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import folium\n",
    "from pandas.io.json import json_normalize"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folium handler positioning at Toronto\n",
    "toronto_map_postal = folium.Map(location=[t_lat, t_lng], zoom_start=10)\n",
    "# adding all the neighbourhoods on the map\n",
    "for lat, lng, label in zip(fd_coordinates_t['Latitude'], fd_coordinates_t['Longitude'], fd_coordinates_t['Postal Code']):\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        fill=True,\n",
    "        color='blue',\n",
    "        fill_color='blue',\n",
    "        fill_opacity=0.6\n",
    "        ).add_to(toronto_map_postal)\n",
    "\n",
    "# GitHub doesn't show the map\n",
    "# unmark line below to see the map if you run this code at supportive platform\n",
    "# toronto_map_postal "
   ]
  },
  {
   "source": [
    "> Apperantly GitHub doesn't load folium map, here is an picture of map\n",
    "\n",
    ">![Image of Toronto Postal Codes](https://jo5u7g.by.files.1drv.com/y4mWVym4oBRWElWVWGHk3IWYJmAYl7BxdGA61FlydQ9UJkhedMrvjKiEIUxk-BqMwbmdCFstcZkh08PCLOeB-Md5wXcYI9HXLRNW4HXl37ETAFMNpOxmQuCBp68Tc3zRavLrhpdGwHzxQlM9sR8eER1qLyuqGOjkIDcUQvUViMvkgqzG5O48c6jSigXGh2DI7ZtkjJbmjXMEQYL2Elxu4T-mw/map.PNG?psid=1)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2.3 Trending Venuse for each postal code at each city\n",
    "\n",
    "\n",
    "> Foursquare has an Python module connecting us to its API. We need need to have an accout at Foursquare to obrain API credentials \n",
    "\n",
    "> You can register your free account at https://foursquare.com/developers/apps\n",
    "\n",
    "> Read about FOursquare module at https://github.com/mLewisLogic/foursquare"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import foursquare\n",
    "\n",
    "CLIENT_ID = '__add yours__' # your Foursquare ID\n",
    "CLIENT_SECRET = '__add yours__' # your Foursquare Secret\n",
    "\n",
    "# used FourSquare module to construct a handler for FourSquare API\n",
    "client = foursquare.Foursquare(client_id=CLIENT_ID, client_secret=CLIENT_SECRET)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 25,
   "outputs": []
  },
  {
   "source": [
    ">### Explore venues at the specific location\n",
    "> client.venues.explore(params={'ll': f'{lat},{lng}', 'section': 'trending', 'limit': '5', 'sortByPopularity': '1'})\n",
    "\n",
    ">- \"ll\" takes Latitude and Longitude of postal code in a city\n",
    "- \"section\" : \"trending\" | give us trending venues at the given postal code location\n",
    "- 'limit': '5' | we get only 5 venues\n",
    "- 'sortByPopularity': '1' | we get only 5 top trending venues\n",
    "\n",
    "> In return for our request we will get a \"JSON\" file, one of its fileds is dedicated to he \"categorie\" of the venue. That files has some extra information. We need to filter that field in order to get a \"clean\" venue categoie. For this we will use a small function below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_type(row):\n",
    "    try:\n",
    "        categories_list = row['categories']\n",
    "    except:\n",
    "        categories_list = row['venue.categories']\n",
    "        \n",
    "    if len(categories_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return categories_list[0]['name']"
   ]
  },
  {
   "source": [
    "> This code makes API calls which are time consuming"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >> Toronto <<\n",
    "df_list_t = []\n",
    "for lat, lng, pcode in zip(fd_coordinates_t['Latitude'], fd_coordinates_t['Longitude'], fd_coordinates_t['Postal Code']):\n",
    "    pcode_json = client.venues.explore(params={'ll': f'{lat},{lng}', 'section': 'trending', 'limit': '5', 'sortByPopularity': '1'})\n",
    "    items = pcode_json['groups'][0]['items']\n",
    "    dataframe = json_normalize(items)   # convert json into Data Frame\n",
    "    dataframe = dataframe[['venue.id', 'venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']]\n",
    "    dataframe['venue.categories'] = dataframe.apply(get_category_type, axis=1) # clean categories fild with our function\n",
    "    dataframe['Postal Code'] = pcode   # add columns representing/connecting venues with postal code\n",
    "    df_list_t.append(dataframe)   # each Date Frame goes to the list for farther murge\n",
    "df_venuse_t = pd.concat(df_list_t) # merge 103 tables in the list into one\n",
    "\n",
    "# >>Chicago<<\n",
    "df_list_c = []\n",
    "for lat, lng, pcode in zip(fd_coordinates_c['Latitude'], fd_coordinates_c['Longitude'], fd_coordinates_c['Postal Code']):\n",
    "    pcode_json = client.venues.explore(params={'ll': f'{lat},{lng}', 'section': 'trending', 'limit': '5', 'sortByPopularity': '1'})\n",
    "    items = pcode_json['groups'][0]['items']\n",
    "    dataframe = json_normalize(items)\n",
    "    dataframe = dataframe[['venue.id', 'venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']]\n",
    "    dataframe['venue.categories'] = dataframe.apply(get_category_type, axis=1)\n",
    "    dataframe['Postal Code'] = pcode\n",
    "    df_list_c.append(dataframe)\n",
    "df_venuse_c = pd.concat(df_list_c)\n",
    "\n",
    "# >> Houston <<\n",
    "df_list_h = []\n",
    "for lat, lng, pcode in zip(fd_coordinates_h['Latitude'], fd_coordinates_h['Longitude'], fd_coordinates_h['Postal Code']):\n",
    "    pcode_json = client.venues.explore(params={'ll': f'{lat},{lng}', 'section': 'trending', 'limit': '5', 'sortByPopularity': '1'})\n",
    "    items = pcode_json['groups'][0]['items']\n",
    "    dataframe = json_normalize(items)\n",
    "    dataframe = dataframe[['venue.id', 'venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']]\n",
    "    dataframe['venue.categories'] = dataframe.apply(get_category_type, axis=1)\n",
    "    dataframe['Postal Code'] = pcode\n",
    "    df_list_h.append(dataframe)\n",
    "df_venuse_h = pd.concat(df_list_h)\n",
    "\n",
    "# >> New Yourk City <<\n",
    "df_list_n = []\n",
    "for lat, lng, pcode in zip(fd_coordinates_n['Latitude'], fd_coordinates_n['Longitude'], fd_coordinates_n['Postal Code']):\n",
    "    pcode_json = client.venues.explore(params={'ll': f'{lat},{lng}', 'section': 'trending', 'limit': '5', 'sortByPopularity': '1'})\n",
    "    items = pcode_json['groups'][0]['items']\n",
    "    dataframe = json_normalize(items)\n",
    "    dataframe = dataframe[['venue.id', 'venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']]\n",
    "    dataframe['venue.categories'] = dataframe.apply(get_category_type, axis=1)\n",
    "    dataframe['Postal Code'] = pcode\n",
    "    df_list_n.append(dataframe)\n",
    "df_venuse_n = pd.concat(df_list_n)"
   ]
  },
  {
   "source": [
    "> Here is how __Toronto__ venues table looks like"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   venue.id              venue.name  venue.categories  \\\n",
       "0  4adf85e1f964a5206e7b21e3            Hudson's Bay  Department Store   \n",
       "1  4ad4c05ef964a520a6f620e3  Nathan Phillips Square             Plaza   \n",
       "2  4ad4c063f964a5201df820e3        Brookfield Place     Shopping Mall   \n",
       "3  4ad7aa49f964a5207b0d21e3     Scotiabank Theatres     Movie Theater   \n",
       "4  4ae5df5af964a520c4a221e3     Bell Trinity Square            Office   \n",
       "\n",
       "   venue.location.lat  venue.location.lng Postal Code  \n",
       "0           43.652040          -79.380391         M1A  \n",
       "1           43.652270          -79.383516         M1A  \n",
       "2           43.646791          -79.378769         M1A  \n",
       "3           43.648829          -79.390782         M1A  \n",
       "4           43.653475          -79.382470         M1A  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>venue.id</th>\n      <th>venue.name</th>\n      <th>venue.categories</th>\n      <th>venue.location.lat</th>\n      <th>venue.location.lng</th>\n      <th>Postal Code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4adf85e1f964a5206e7b21e3</td>\n      <td>Hudson's Bay</td>\n      <td>Department Store</td>\n      <td>43.652040</td>\n      <td>-79.380391</td>\n      <td>M1A</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4ad4c05ef964a520a6f620e3</td>\n      <td>Nathan Phillips Square</td>\n      <td>Plaza</td>\n      <td>43.652270</td>\n      <td>-79.383516</td>\n      <td>M1A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4ad4c063f964a5201df820e3</td>\n      <td>Brookfield Place</td>\n      <td>Shopping Mall</td>\n      <td>43.646791</td>\n      <td>-79.378769</td>\n      <td>M1A</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4ad7aa49f964a5207b0d21e3</td>\n      <td>Scotiabank Theatres</td>\n      <td>Movie Theater</td>\n      <td>43.648829</td>\n      <td>-79.390782</td>\n      <td>M1A</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4ae5df5af964a520c4a221e3</td>\n      <td>Bell Trinity Square</td>\n      <td>Office</td>\n      <td>43.653475</td>\n      <td>-79.382470</td>\n      <td>M1A</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "df_venuse_t.head()"
   ]
  },
  {
   "source": [
    "> Top 10 venues categories at __Toronto__"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Shopping Mall       127\n",
       "Grocery Store       106\n",
       "Plaza                89\n",
       "Department Store     88\n",
       "Movie Theater        84\n",
       "Office               80\n",
       "Supermarket          74\n",
       "Park                 57\n",
       "Pharmacy             30\n",
       "Coffee Shop          25\n",
       "Name: venue.categories, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "df_venuse_t['venue.categories'].value_counts().head(10)"
   ]
  },
  {
   "source": [
    "### 2.4 Now lets map all the trending venuse at each city on the Folium map"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    ">__Toronto's__ trending venues "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_ven_t = folium.Map(location=[t_lat, t_lng], zoom_start=10)\n",
    "for lat, lng, label in zip(df_venuse_t['venue.location.lat'], df_venuse_t['venue.location.lng'], df_venuse_t['venue.name']):\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=3,\n",
    "        popup=label,\n",
    "        fill=True,\n",
    "        color='green',\n",
    "        fill_color='red',\n",
    "        fill_opacity=0.5\n",
    "        ).add_to(map_ven_t)\n",
    "\n",
    "# GitHub doesn't show the map\n",
    "# unmark line below to see the map if you run this code at supportive platform\n",
    "# map_ven_t"
   ]
  },
  {
   "source": [
    "> Apperantly GitHub doesn't load Folium map, here is a picture of map\n",
    "\n",
    "<img src=\"https://ly5n7g.by.files.1drv.com/y4mXMFRM7fkmqL-SD_kqmbDSffzSxlcX3sHE7Czx7y-5ex8h40ohM1lEuFi28EQzmw_Lnlc8ANp7AdRsIhvpiW7y9Apj4vTpbWTNoLNPgv7VO1cNKiqdVostT9djKCXaOZgPoHcWzjUn79AyWJgj4i2dknduk9zfLbx_DG29_ebuEyz5iEWa69Poi8ueaf53WrkVGWsz-X2EMCaHhLDDdGMXA/tor_map_ven.PNG?psid=1\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    ">__Chicago's__ trending venues"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_ven_c = folium.Map(location=[c_lat, c_lng], zoom_start=10)\n",
    "for lat, lng, label in zip(df_venuse_c['venue.location.lat'], df_venuse_c['venue.location.lng'], df_venuse_c['venue.name']):\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=3,\n",
    "        popup=label,\n",
    "        fill=True,\n",
    "        color='green',\n",
    "        fill_color='red',\n",
    "        fill_opacity=0.5\n",
    "        ).add_to(map_ven_c)\n",
    "\n",
    "# GitHub doesn't show the map\n",
    "# unmark line below to see the map if you run this code at supportive platform\n",
    "# map_ven_c"
   ]
  },
  {
   "source": [
    "> Apperantly GitHub doesn't load Folium map, here is a picture of map\n",
    "\n",
    "><img src=\"https://li5p7g.by.files.1drv.com/y4mNui2N8HZWIPboVt2rOxKxNHSqefpzvdMuo25-6jcPKaZh0Shr6Ead7SFtQQyNyy_m123IeG6D9C5gziMAmBMbi-m8Y5gLdIOdWuOFx_v2Nf-z6BZH38kE_cancYRFrzrPYO-HUHWZ507BK08pYLWkJOT8sJgm6t3bXRo4iLuJ7jUgaY346ALA0DSidhsIDCrskem9WfbPWcC1IfMaE4asA/cgo_map_ven.PNG?psid=1\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    ">__Houston's__ trending venues"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_ven_h = folium.Map(location=[h_lat, h_lng], zoom_start=10)\n",
    "for lat, lng, label in zip(df_venuse_h['venue.location.lat'], df_venuse_h['venue.location.lng'], df_venuse_h['venue.name']):\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=3,\n",
    "        popup=label,\n",
    "        fill=True,\n",
    "        color='green',\n",
    "        fill_color='red',\n",
    "        fill_opacity=0.5\n",
    "        ).add_to(map_ven_h)\n",
    "\n",
    "# GitHub doesn't show the map\n",
    "# unmark line below to see the map if you run this code at supportive platform\n",
    "# map_ven_h"
   ]
  },
  {
   "source": [
    "> Apperantly GitHub doesn't load Folium map, here is a picture of map\n",
    "\n",
    "><img src=\"https://li5i7g.by.files.1drv.com/y4myDCJBSHGcPJEVK4fz7_dB8CkI8uNQM4lld93jKrrgEBuS2JXQdzcik5DF7mOIFiMsFuteG2oEIbGM2DDE2RV4sP4TWYlqKgzJP0NZoRlxp_xxcIEtZZEVy__JGEubQRDOpMBMpJS1LUvjg_r7fDYq8FM_nFSZbGs7yPUwFpPHbmjNFRsK6jHn5pNGH5M1bRaIng683w_BS08iaxnqPdtHg/hstn_map_ven.PNG?psid=1\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    ">__NYC's__ trending venues"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_ven_n = folium.Map(location=[n_lat, n_lng], zoom_start=10)\n",
    "for lat, lng, label in zip(df_venuse_n['venue.location.lat'], df_venuse_n['venue.location.lng'], df_venuse_n['venue.name']):\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=3,\n",
    "        popup=label,\n",
    "        fill=True,\n",
    "        color='green',\n",
    "        fill_color='red',\n",
    "        fill_opacity=0.5\n",
    "        ).add_to(map_ven_n)\n",
    "\n",
    "# GitHub doesn't show the map\n",
    "# unmark line below to see the map if you run this code at supportive platform\n",
    "# map_ven_n"
   ]
  },
  {
   "source": [
    "> Apperantly GitHub doesn't load Folium map, here is a picture of __NYC__ map\n",
    "\n",
    "><img src=\"https://ly5m7g.by.files.1drv.com/y4mCPyOxbZHGt_fvDxdVV8WOLXSLZNArvh9gGdBpH8QXUt_0VrTDk4dJCwO07hasXH_WTr4dudR06Dst07MWW705yKoQ0oHX8iYjIUWvWyGWQAO-3N9vlZRk1zEIo0vx7ueT9_S7QV7ak9Rykq7VbfuNPiW50JB2M-geQ9oUmgQW7Tol61seVmUqAxEGU0UwFYU3dSRd_KKgAYj0OnW-Z2a4w/nyc_map_ven.PNG?psid=1\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3. Postal Codes Clustering using DBSCAN & scikit-learn\n",
    "\n",
    ">DBSCAN stands for Density-Based Spatial Clustering of Applications with Noise. This technique is one of the most common clustering algorithms  which works based on density of object.\n",
    "The whole idea is that if a particular point belongs to a cluster, it should be near to lots of other points in that cluster.\n",
    "\n",
    ">It works based on two parameters: Epsilon and Minimum Points  \n",
    ">>**Epsilon** determine a specified radius that if includes enough number of points within, we call it dense area  \n",
    "**minimumSamples** determine the minimum number of data points we want in a neighborhood to define a cluster.\n",
    "\n",
    ">DBSCAN is specially very good for tasks like class identification on a spatial context. The wonderful attribute of DBSCAN algorithm is that it can find out any arbitrary shape cluster without getting affected by noise. For example, this following example cluster the location of postal codes can be used here, for instance, to find the group of venues within the same procsimity. As you can see, it not only finds different arbitrary shaped clusters, can find the denser part of data-centered samples by ignoring less-dense areas or noises."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import sklearn.utils\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "source": [
    "# TORONTO\n",
    "sklearn.utils.check_random_state(1000)\n",
    "Clus_dataSet_t = df_venuse_t[['venue.location.lat','venue.location.lng']]\n",
    "Clus_dataSet_t = np.nan_to_num(Clus_dataSet_t)\n",
    "Clus_dataSet_t = StandardScaler().fit_transform(Clus_dataSet_t)\n",
    "\n",
    "# Compute DBSCAN\n",
    "db_t = DBSCAN(eps=0.2, min_samples=10).fit(Clus_dataSet_t)\n",
    "# Firts, create an array of booleans using the labels from db.\n",
    "core_samples_mask_t = np.zeros_like(db_t.labels_, dtype=bool)\n",
    "core_samples_mask_t[db_t.core_sample_indices_] = True\n",
    "labels_t = db_t.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "realClusterNum_t = len(set(labels_t)) - (1 if -1 in labels_t else 0)\n",
    "clusterNum_t = len(set(labels_t))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Toronto has 14 vibrant clusters.\nChicago has 7 vibrant clusters.\nHouston has 2 vibrant clusters.\nNYC has 15 vibrant clusters.\n"
     ]
    }
   ],
   "source": [
    "# CHICAGO\n",
    "Clus_dataSet_c = df_venuse_c[['venue.location.lat','venue.location.lng']]\n",
    "Clus_dataSet_c = np.nan_to_num(Clus_dataSet_c)\n",
    "Clus_dataSet_c = StandardScaler().fit_transform(Clus_dataSet_c)\n",
    "db_c = DBSCAN(eps=0.2, min_samples=10).fit(Clus_dataSet_c)\n",
    "core_samples_mask_c = np.zeros_like(db_c.labels_, dtype=bool)\n",
    "core_samples_mask_c[db_c.core_sample_indices_] = True\n",
    "labels_c = db_c.labels_\n",
    "realClusterNum_c=len(set(labels_c)) - (1 if -1 in labels_c else 0)\n",
    "clusterNum_c = len(set(labels_c))\n",
    "\n",
    "# HOUSTON\n",
    "Clus_dataSet_h = df_venuse_h[['venue.location.lat','venue.location.lng']]\n",
    "Clus_dataSet_h = np.nan_to_num(Clus_dataSet_h)\n",
    "Clus_dataSet_h = StandardScaler().fit_transform(Clus_dataSet_h)\n",
    "db_h = DBSCAN(eps=0.2, min_samples=10).fit(Clus_dataSet_h)\n",
    "core_samples_mask_h = np.zeros_like(db_h.labels_, dtype=bool)\n",
    "core_samples_mask_h[db_h.core_sample_indices_] = True\n",
    "labels_h = db_h.labels_\n",
    "realClusterNum_h = len(set(labels_h)) - (1 if -1 in labels_h else 0)\n",
    "clusterNum_h = len(set(labels_h))\n",
    "\n",
    "# NYC\n",
    "Clus_dataSet_n = df_venuse_n[['venue.location.lat','venue.location.lng']]\n",
    "Clus_dataSet_n = np.nan_to_num(Clus_dataSet_n)\n",
    "Clus_dataSet_n = StandardScaler().fit_transform(Clus_dataSet_n)\n",
    "db_n = DBSCAN(eps=0.2, min_samples=10).fit(Clus_dataSet_n)\n",
    "core_samples_mask_n = np.zeros_like(db_n.labels_, dtype=bool)\n",
    "core_samples_mask_n[db_n.core_sample_indices_] = True\n",
    "labels_n = db_n.labels_\n",
    "realClusterNum_n = len(set(labels_n)) - (1 if -1 in labels_n else 0)\n",
    "clusterNum_n = len(set(labels_n))\n",
    "\n",
    "print(f'Toronto has {clusterNum_t} vibrant clusters.')\n",
    "print(f'Chicago has {clusterNum_c} vibrant clusters.')\n",
    "print(f'Houston has {clusterNum_h} vibrant clusters.')\n",
    "print(f'NYC has {clusterNum_n} vibrant clusters.')"
   ]
  },
  {
   "source": [
    "### 3.2 Cluster visualization\n",
    "\n",
    "> This computation is time consuming"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "> __Toronto__ DBSCAN plot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_t = plt.cm.Spectral(np.linspace(0, 1, len(labels_t)))\n",
    "# Plot the points with colors\n",
    "for k, col in zip(labels_t, colors_t):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = 'k'\n",
    "\n",
    "    class_member_mask_t = (labels_t == k)\n",
    "\n",
    "    # Plot the datapoints that are clustered\n",
    "    xy = Clus_dataSet_t[class_member_mask_t & core_samples_mask_t]\n",
    "    # plt.scatter(xy[:, 0], xy[:, 1],s=30, c=[col], marker=u'o', alpha=0.5)\n",
    "\n",
    "    # Plot the outliers\n",
    "    xy = Clus_dataSet_t[class_member_mask_t & ~core_samples_mask_t]\n",
    "    # plt.scatter(xy[:, 0], xy[:, 1],s=30, c=[col], marker=u'o', alpha=0.5)"
   ]
  },
  {
   "source": [
    "> Apperantly GitHub doesn't load Folium MatPlotLib plots, here is a picture of Toronto plot\n",
    "\n",
    "><img src=\"https://li5v7g.by.files.1drv.com/y4mstDes1Nk9Eec6G-FE0b7VGJszG_AVEB5PBlMdCLIbUuYim1jektQShZML9WU8SrioQke4yJjvlAhagp-z1jkJ2zLjkwszlWdtSmAVgFvMuhrEMwiEckdshReSVz3ttDKsAI56kIoi3pT7ONfIgOqXi7URMEyenJ0OI5w2--49HDurib2rmNKjvaJmVe7ocy904xqoVyCAmbK45z2oCc7Ug/tor_map_dbscan.PNG?psid=1\" alt=\"Drawing\" style=\"width: 370px;\"/>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "> __Chicago__ DBSCAN plot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_c = plt.cm.Spectral(np.linspace(0, 1, len(labels_c)))\n",
    "for k, col in zip(labels_c, colors_c):\n",
    "    if k == -1:\n",
    "        col = 'k'\n",
    "\n",
    "    class_member_mask_c = (labels_c == k)\n",
    "    xy = Clus_dataSet_c[class_member_mask_c & core_samples_mask_c]\n",
    "    # plt.scatter(xy[:, 0], xy[:, 1],s=30, c=[col], marker=u'o', alpha=0.5)\n",
    "    xy = Clus_dataSet_c[class_member_mask_c & ~core_samples_mask_c]\n",
    "    # plt.scatter(xy[:, 0], xy[:, 1],s=30, c=[col], marker=u'o', alpha=0.5)"
   ]
  },
  {
   "source": [
    "> Apperantly GitHub doesn't load Folium MatPlotLib plots, here is a picture of Chicago plot\n",
    "\n",
    "><img src=\"https://li5m7g.by.files.1drv.com/y4mzCnYTweTzf3BC5YlMO_RS4aFKZ__F-gZqHF1mPGFploCh3BlUsDHpwkCopJ1JfOiXPgptveWZToaYlG1Lkm49w0bXF9fofxGYrv-O-n7Kfa9XpxrTHhnHDtNQHkPGkgO-cb1X694Ho85VYayhEQaTuLtQVy6XCuUBPK42W12dAF0HAHzGYMfDd_CLWlZcmodLe5og5hCJA_MPuRShzibCw/cgo_map_dbscan.PNG?psid=1\" alt=\"Drawing\" style=\"width: 370px;\"/>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "> __Houston__ DBSCAN plot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_h = plt.cm.Spectral(np.linspace(0, 1, len(labels_h)))\n",
    "for k, col in zip(labels_h, colors_h):\n",
    "    if k == -1:\n",
    "        col = 'k'\n",
    "\n",
    "    class_member_mask_h = (labels_h == k)\n",
    "    xy = Clus_dataSet_h[class_member_mask_h & core_samples_mask_h]\n",
    "    # plt.scatter(xy[:, 0], xy[:, 1],s=30, c=[col], marker=u'o', alpha=0.5)\n",
    "    xy = Clus_dataSet_h[class_member_mask_h & ~core_samples_mask_h]\n",
    "    # plt.scatter(xy[:, 0], xy[:, 1],s=30, c=[col], marker=u'o', alpha=0.5)"
   ]
  },
  {
   "source": [
    "> Apperantly GitHub doesn't load Folium MatPlotLib plots, here is a picture of Chicago plot\n",
    "\n",
    "><img src=\"https://li5o7g.by.files.1drv.com/y4mSBzboX8MhOnm6IT6BLKxr7aa7sN7w2FZqQ4VkZGfiGJNWSxrXttOYcW_1cCZc0Iaucy29Tm2TZ_7OZV0W4APaQ1n4Ul2ZQ4a238WbZKrsy8_wa8ynGlZu3MUiVgBXyuZGjLVNyCySdgKTTsVxVGsbQ7lQcL1jkgb9qRdXYaAoR4VOokKZonba2TSjcaG8WZLnBJRK-lH03x7stI0MngOCw/hstn_map_dbscan.PNG?psid=1\" alt=\"Drawing\" style=\"width: 370px;\"/>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "> __NYC__ DBSCAN plot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_n = plt.cm.Spectral(np.linspace(0, 1, len(labels_n)))\n",
    "for k, col in zip(labels_n, colors_n):\n",
    "    if k == -1:\n",
    "        col = 'k'\n",
    "\n",
    "    class_member_mask_n = (labels_n == k)\n",
    "    # xy = Clus_dataSet_n[class_member_mask_n & core_samples_mask_n]\n",
    "    plt.scatter(xy[:, 0], xy[:, 1],s=30, c=[col], marker=u'o', alpha=0.5)\n",
    "    xy = Clus_dataSet_n[class_member_mask_n & ~core_samples_mask_n]\n",
    "    # plt.scatter(xy[:, 0], xy[:, 1],s=30, c=[col], marker=u'o', alpha=0.5)"
   ]
  },
  {
   "source": [
    "> Apperantly GitHub doesn't load Folium MatPlotLib plots, here is a picture of __NYC__ plot\n",
    "\n",
    "><img src=\"https://li5l7g.by.files.1drv.com/y4mO1mUa3feBM9i6cg_IRK78-4icHBFuotL_hzWSoZi7rr6NtWnXVbAchzGTHy290NmzaycboDzZtdF4b14kk2NI7e_0dnKt1x_nhhcTrUivtOoP-fFKMZHK3B2_f_0HDwW6UGGD3w_dmcH-mK1GxstB6i-nuqT7ArUFI9jEEpkLYuF3IJqji6632bNxHw8rO8k_ieQgOHv0s3-tZIa9yBMmQ/nyc_map_dbscan.PNG?psid=1\" alt=\"Drawing\" style=\"width: 370px;\"/>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 3.3 Mark each venue in a Data Frame with its cluster if the venu has one"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   venue.id              venue.name  venue.categories  \\\n",
       "0  4adf85e1f964a5206e7b21e3            Hudson's Bay  Department Store   \n",
       "1  4ad4c05ef964a520a6f620e3  Nathan Phillips Square             Plaza   \n",
       "2  4ad4c063f964a5201df820e3        Brookfield Place     Shopping Mall   \n",
       "3  4ad7aa49f964a5207b0d21e3     Scotiabank Theatres     Movie Theater   \n",
       "4  4ae5df5af964a520c4a221e3     Bell Trinity Square            Office   \n",
       "\n",
       "   venue.location.lat  venue.location.lng Postal Code  ClusterNumber  \n",
       "0           43.652040          -79.380391         M1A              0  \n",
       "1           43.652270          -79.383516         M1A              0  \n",
       "2           43.646791          -79.378769         M1A              0  \n",
       "3           43.648829          -79.390782         M1A              0  \n",
       "4           43.653475          -79.382470         M1A              0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>venue.id</th>\n      <th>venue.name</th>\n      <th>venue.categories</th>\n      <th>venue.location.lat</th>\n      <th>venue.location.lng</th>\n      <th>Postal Code</th>\n      <th>ClusterNumber</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4adf85e1f964a5206e7b21e3</td>\n      <td>Hudson's Bay</td>\n      <td>Department Store</td>\n      <td>43.652040</td>\n      <td>-79.380391</td>\n      <td>M1A</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4ad4c05ef964a520a6f620e3</td>\n      <td>Nathan Phillips Square</td>\n      <td>Plaza</td>\n      <td>43.652270</td>\n      <td>-79.383516</td>\n      <td>M1A</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4ad4c063f964a5201df820e3</td>\n      <td>Brookfield Place</td>\n      <td>Shopping Mall</td>\n      <td>43.646791</td>\n      <td>-79.378769</td>\n      <td>M1A</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4ad7aa49f964a5207b0d21e3</td>\n      <td>Scotiabank Theatres</td>\n      <td>Movie Theater</td>\n      <td>43.648829</td>\n      <td>-79.390782</td>\n      <td>M1A</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4ae5df5af964a520c4a221e3</td>\n      <td>Bell Trinity Square</td>\n      <td>Office</td>\n      <td>43.653475</td>\n      <td>-79.382470</td>\n      <td>M1A</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# TORONTO\n",
    "df_venuse_t['ClusterNumber'] = labels_t\n",
    "data_filter_t = df_venuse_t['ClusterNumber'] != -1 # cluster \"-1\" is for venuse outliers\n",
    "df_cluster_t = df_venuse_t.where(data_filter_t).dropna()\n",
    "\n",
    "# CHICAGO\n",
    "df_venuse_c['ClusterNumber'] = labels_c\n",
    "data_filter_c = df_venuse_c['ClusterNumber'] != -1\n",
    "df_cluster_c = df_venuse_c.where(data_filter_c).dropna()\n",
    "\n",
    "# HOUSTON\n",
    "df_venuse_h['ClusterNumber'] = labels_h\n",
    "data_filter_h = df_venuse_h['ClusterNumber'] != -1\n",
    "df_cluster_h = df_venuse_h.where(data_filter_h).dropna()\n",
    "\n",
    "# NYC\n",
    "df_venuse_n['ClusterNumber'] = labels_n\n",
    "data_filter_n = df_venuse_n['ClusterNumber'] != -1\n",
    "df_cluster_n = df_venuse_n.where(data_filter_n).dropna()\n",
    "\n",
    "# how Toronto's table looks like\n",
    "df_venuse_t.head()"
   ]
  },
  {
   "source": [
    "## 4. Looking for city clusters with trending venues as a coffee shop"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "> To remind how many total clusters each city has:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Toronto has 14 vibrant clusters.\nChicago has 7 vibrant clusters.\nHouston has 2 vibrant clusters.\nNYC has 15 vibrant clusters.\n"
     ]
    }
   ],
   "source": [
    "print(f'Toronto has {clusterNum_t} vibrant clusters.')\n",
    "print(f'Chicago has {clusterNum_c} vibrant clusters.')\n",
    "print(f'Houston has {clusterNum_h} vibrant clusters.')\n",
    "print(f'NYC has {clusterNum_n} vibrant clusters.')"
   ]
  },
  {
   "source": [
    "> Not all of these clusters have coffee shops among its venues, lets find out which clusters are relevant"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TORONTO has 4 coffee cluster from total of 14.\nCHICAGO has 4 coffee cluster from total of 7.\nHOUSTON has 1 coffee cluster from total of 2.\nNYC has 4 coffee cluster from total of 15.\n"
     ]
    }
   ],
   "source": [
    "# TORONTO\n",
    "test_t = df_cluster_t[['venue.categories', 'ClusterNumber']]\n",
    "test_t = test_t[['venue.categories', 'ClusterNumber']].where(df_cluster_t['venue.categories'] == 'Coffee Shop').dropna()\n",
    "rename_t = {'index': 'Cluster', 'venue.categories': 'Total Coffee shops'}\n",
    "df_coffee_cluster_t = test_t.ClusterNumber.value_counts().reset_index(name='venue.categories').rename(columns=rename_t)\n",
    "coffee_clusters_t = df_coffee_cluster_t['Cluster'].values\n",
    "print(f'TORONTO has {len(coffee_clusters_t)} coffee cluster from total of {clusterNum_t}.')\n",
    "\n",
    "# CHICAGO\n",
    "test_c = df_cluster_c[['venue.categories', 'ClusterNumber']]\n",
    "test_c = test_c[['venue.categories', 'ClusterNumber']].where(df_cluster_c['venue.categories'] == 'Coffee Shop').dropna()\n",
    "rename_c = {'index': 'Cluster', 'venue.categories': 'Total Coffee shops'}\n",
    "df_coffee_cluster_c = test_c.ClusterNumber.value_counts().reset_index(name='venue.categories').rename(columns=rename_c)\n",
    "coffee_clusters_c = df_coffee_cluster_c['Cluster'].values\n",
    "print(f'CHICAGO has {len(coffee_clusters_c)} coffee cluster from total of {clusterNum_c}.')\n",
    "\n",
    "# HOUSTON\n",
    "test_h = df_cluster_h[['venue.categories', 'ClusterNumber']]\n",
    "test_h = test_h[['venue.categories', 'ClusterNumber']].where(df_cluster_h['venue.categories'] == 'Coffee Shop').dropna()\n",
    "rename_h = {'index': 'Cluster', 'venue.categories': 'Total Coffee shops'}\n",
    "df_coffee_cluster_h = test_h.ClusterNumber.value_counts().reset_index(name='venue.categories').rename(columns=rename_h)\n",
    "coffee_clusters_h = df_coffee_cluster_h['Cluster'].values\n",
    "print(f'HOUSTON has {len(coffee_clusters_h)} coffee cluster from total of {clusterNum_h}.')\n",
    "\n",
    "# NYC\n",
    "test_n = df_cluster_n[['venue.categories', 'ClusterNumber']]\n",
    "test_n = test_n[['venue.categories', 'ClusterNumber']].where(df_cluster_n['venue.categories'] == 'Coffee Shop').dropna()\n",
    "rename_n = {'index': 'Cluster', 'venue.categories': 'Total Coffee shops'}\n",
    "df_coffee_cluster_n = test_n.ClusterNumber.value_counts().reset_index(name='venue.categories').rename(columns=rename_n)\n",
    "coffee_clusters_n = df_coffee_cluster_n['Cluster'].values\n",
    "print(f'NYC has {len(coffee_clusters_n)} coffee cluster from total of {clusterNum_n}.')"
   ]
  },
  {
   "source": [
    ">__Observation__: Looks like at the south cities like Houston people don't drink that much coffee, at least they don't do it at that many locations as nothern cities do. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 5. Mapping Coffe Clusters \n",
    "\n",
    ">For each city cluster, we need to calculate geo coordinates to map its center on the Folium map. We can do that by calculating the mean latitude and mean longitude of all venues in the coffee clusters."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    ClusterNumber  venue.location.lat  venue.location.lng\n",
       "0             0.0           43.651413          -79.382973\n",
       "9             9.0           43.680916          -79.415979\n",
       "11           11.0           43.642784          -79.422971\n",
       "12           12.0           43.738982          -79.588984"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ClusterNumber</th>\n      <th>venue.location.lat</th>\n      <th>venue.location.lng</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>43.651413</td>\n      <td>-79.382973</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9.0</td>\n      <td>43.680916</td>\n      <td>-79.415979</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11.0</td>\n      <td>43.642784</td>\n      <td>-79.422971</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12.0</td>\n      <td>43.738982</td>\n      <td>-79.588984</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "# TORONTO\n",
    "# short table of all venues\n",
    "df_cluster_loc_t = df_cluster_t[['venue.location.lat', 'venue.location.lng', 'ClusterNumber']]\n",
    "# short table of all cluster with mean coordinates\n",
    "df_cluster_loc_t = df_cluster_loc_t.groupby(by='ClusterNumber', as_index=False).mean()\n",
    "# only clusters with trending Coffee shops\n",
    "df_coffe_cluster_t = df_cluster_loc_t[df_cluster_loc_t['ClusterNumber'].isin(coffee_clusters_t)]\n",
    "\n",
    "# CHICAGO\n",
    "df_cluster_loc_c = df_cluster_c[['venue.location.lat', 'venue.location.lng', 'ClusterNumber']]\n",
    "df_cluster_loc_c = df_cluster_loc_c.groupby(by='ClusterNumber', as_index=False).mean()\n",
    "df_coffe_cluster_c = df_cluster_loc_c[df_cluster_loc_c['ClusterNumber'].isin(coffee_clusters_c)]\n",
    "\n",
    "# HOUSTON\n",
    "df_cluster_loc_h = df_cluster_h[['venue.location.lat', 'venue.location.lng', 'ClusterNumber']]\n",
    "df_cluster_loc_h = df_cluster_loc_h.groupby(by='ClusterNumber', as_index=False).mean()\n",
    "df_coffe_cluster_h = df_cluster_loc_h[df_cluster_loc_h['ClusterNumber'].isin(coffee_clusters_h)]\n",
    "\n",
    "# NYC\n",
    "df_cluster_loc_n = df_cluster_n[['venue.location.lat', 'venue.location.lng', 'ClusterNumber']]\n",
    "df_cluster_loc_n = df_cluster_loc_n.groupby(by='ClusterNumber', as_index=False).mean()\n",
    "df_coffe_cluster_n = df_cluster_loc_n[df_cluster_loc_n['ClusterNumber'].isin(coffee_clusters_n)]\n",
    "\n",
    "# look at Toronto's table\n",
    "df_coffe_cluster_t"
   ]
  },
  {
   "source": [
    "> Now let's map the coffee clusters on the Folium mat to see where are those areas are located.\n",
    "\n",
    "> TORONTO COFFEE AREAS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map only Coffe Shop clusters\n",
    "t_map_coffe_cluster = folium.Map(location=[t_lat, t_lng], zoom_start=11)\n",
    "for lat, lng, label in zip(df_coffe_cluster_t['venue.location.lat'], df_coffe_cluster_t['venue.location.lng'], df_coffe_cluster_t['ClusterNumber']):\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=25,\n",
    "        popup=label,\n",
    "        tooltip=label,\n",
    "        fill=True,\n",
    "        color='red',\n",
    "        fill_color='red',\n",
    "        fill_opacity=0.5\n",
    "        ).add_to(t_map_coffe_cluster)\n",
    "\n",
    "# GitHub doesn't show the map\n",
    "# unmark line below to see the map if you run this code at supportive platform\n",
    "# t_map_coffe_cluster"
   ]
  },
  {
   "source": [
    "> Apperantly GitHub doesn't load Folium map, here is a picture of __TORONTO__ COFFEE map\n",
    "\n",
    "><img src=\"https://li5u7g.by.files.1drv.com/y4m5H-xUnjCw9awl0f9sBhFSMv-6dV6ndjSkEogsZiYG7TizCvomFLKOIbQBKP44JGHuiWSxQiR1Tj43CU8eskziMzV5e4ZjCvJypkfVgynGg0qUVfMKBcjPrFs2uIGDY3c40EfMR-wBb667eWLSCVXPFKg7PVdg1coiPzDfsX5wv-WQdPg_27zAG8KZHBxQSmPMV6SPLWxqsNKSRDpk3Fwpw/tor_map_rec.PNG?psid=1\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    ">__CHICAGO__ COFFEE AREAS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map only Coffe Shop clusters\n",
    "c_map_coffe_cluster = folium.Map(location=[c_lat, c_lng], zoom_start=11)\n",
    "for lat, lng, label in zip(df_coffe_cluster_c['venue.location.lat'], df_coffe_cluster_c['venue.location.lng'], df_coffe_cluster_c['ClusterNumber']):\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=25,\n",
    "        popup=label,\n",
    "        tooltip=label,\n",
    "        fill=True,\n",
    "        color='red',\n",
    "        fill_color='red',\n",
    "        fill_opacity=0.5\n",
    "        ).add_to(c_map_coffe_cluster)\n",
    "\n",
    "# GitHub doesn't show the map\n",
    "# unmark line below to see the map if you run this code at supportive platform\n",
    "# c_map_coffe_cluster"
   ]
  },
  {
   "source": [
    "> Apperantly GitHub doesn't load Folium map, here is a picture of CHICAGO COFFEE map\n",
    "\n",
    "><img src=\"https://li5n7g.by.files.1drv.com/y4m_PXDgUKPXh9Hcijw1dzRMpS5irFY5WBWClMV5M_MiDbarhlPOrTQ9HIbBtQchULJkjQJoVsAOhuUw6XcMbk_sFMxMyGTllmpLGz4jEDWFLq1bkOvWW2ZVNDQqLBPaccOVf7fFTmMblZ_Rzdyzpnr7Ifx4LeuaL9HkRuJ1Dr5qJUZo8gUsPdGjwl08VXzj_7FgX1l8wVg3Y89pOPedYCWPw/cgo_map_rec.PNG?psid=1\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    ">__HOUSTON__ COFFEE AREAS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map only Coffe Shop clusters\n",
    "h_map_coffe_cluster = folium.Map(location=[h_lat, h_lng], zoom_start=11)\n",
    "for lat, lng, label in zip(df_coffe_cluster_h['venue.location.lat'], df_coffe_cluster_h['venue.location.lng'], df_coffe_cluster_h['ClusterNumber']):\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=25,\n",
    "        popup=label,\n",
    "        tooltip=label,\n",
    "        fill=True,\n",
    "        color='red',\n",
    "        fill_color='red',\n",
    "        fill_opacity=0.5\n",
    "        ).add_to(h_map_coffe_cluster)\n",
    "\n",
    "# GitHub doesn't show the map\n",
    "# unmark line below to see the map if you run this code at supportive platform\n",
    "# h_map_coffe_cluster"
   ]
  },
  {
   "source": [
    "> Apperantly GitHub doesn't load Folium map, here is a picture of HOUSTON COFFEE map\n",
    "\n",
    "><img src=\"https://li5j7g.by.files.1drv.com/y4mafOAhj3a7n7b1RTKtoI3XGwV0_lwVP5rhn0rnXiG-DddMfXSt-SLh3DeBlXWzD4B9Up9VUTOZyTrfCviLPH6cIUO4Z9dceTxJzTq8mmFc99xTS5hSr763AOcGqKUDoGikeVlMt3LYyXs0bsoREZBn6u0scYCak1hZMTuU2lgtJCAENEHehpA4ebZXiDnnmlceF38fyoTA0eFMzNaGYlatQ/hstn_map_rec.PNG?psid=1\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    ">__NEW YORK CITY__ COFFEE AREAS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_map_coffe_cluster = folium.Map(location=[n_lat, n_lng], zoom_start=11)\n",
    "for lat, lng, label in zip(df_coffe_cluster_n['venue.location.lat'], df_coffe_cluster_n['venue.location.lng'], df_coffe_cluster_n['ClusterNumber']):\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=25,\n",
    "        popup=label,\n",
    "        tooltip=label,\n",
    "        fill=True,\n",
    "        color='red',\n",
    "        fill_color='red',\n",
    "        fill_opacity=0.5\n",
    "        ).add_to(n_map_coffe_cluster)\n",
    "\n",
    "# GitHub doesn't show the map\n",
    "# unmark line below to see the map if you run this code at supportive platform\n",
    "# n_map_coffe_cluster"
   ]
  },
  {
   "source": [
    "> Apperantly GitHub doesn't load Folium map, here is a picture of NYC COFFEE map\n",
    "\n",
    "><img src=\"https://li5k7g.by.files.1drv.com/y4mLRgtb0YKhjg03tOUO5EdheOYY-9FHU67LfqwYvK_FmiGiMB0RKUfvl2ZXuAZBUp8XR-r4Whlusb5FSsviz2pgwAxZhpDm16RTZot6Bmq6y3VUvsRLFo0t8eyW_D-eHHz0JevXsZrfVdFybgnG_3MNv77llXAjalaPpnzmmJ2YQWMcALV4giOAOmigdvs2o28L1J4Ss7yuAQnBz9r6-2Pjg/nyc_map_rec.PNG?psid=1\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 6. Discussion section\n",
    "\n",
    "We found that all the reserved cities in the project have coffee shop trending areas. Apparently, 3 of 4 cities have exactly 4 coffee clusters and only Houston has 1 coffee cluster. Perhaps, at the moment of the research, it was hot enough for the people of Houston to stay away from hot drinks like coffee =) Anyways, the rest of the cities demonstrated 1 of 4 clusters tend to belong to so-called downtown areas. Perhaps, those are the areas with an in-office workforce.\n",
    "\n",
    "The other 3 clusters can be characterized as mainly residential. Perhaps people work from homes in those areas and consume at nearby venues, including the coffee shops.\n",
    "\n",
    "Depends on the prospects of current health craziest, work from home could be a long-term trend. Therefore, residential areas might be a meaningful goal for the new venues like coffee shops."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "All the downtown coffee areas might make seance if those areas don't have strong present competition.\n",
    "\n",
    "All the residential areas might provide a better competition perspective. However, there is a potential real state defecate at those locations. Many people tend to consume services within 10 minutes drive near their dwelling or nearby local shopping plaza--which might be a good option in our case."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}