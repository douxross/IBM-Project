{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Capstone Project: search for a location\n",
    "\n",
    "### 1.1 A description of the problem and a discussion of the background"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We want to open one coffee shop at 3 locations--Toronto (Canada), Chicago (US), Houston (US), and New York City (USA). All those three cities within the 2 to 3 million population range, except NYC--which is above 8 million. We want to find location options for one coffee shop in each city. We would like to open our coffee shop in the established coffee-lovers area with strong human traffic. Our approach isn't the optimal solution, however, it can be useful to get yourself familiar with potential areas for our business project. Also, the obtained data can be an optional backing base among others as data-driven support for protentional investors. If our data does not line up with expert's opinions on where to start our new coffee shop we could use our data as a good point to question any reals state expert recommendation. It is good to know what kind of data an expert has to make our data look less relevant.\n",
    "\n",
    "Overall, the data from our project can be a starting point to find a local real state expert in the recommended areas.\n",
    "\n",
    "Many companies are practicing remote \"office\" when workers stay and work from home. Due to decried demand for coffee at regular office locations, we can assume that that demand is redistributed among living areas--near staying at-home workers. Out model suppose to spot this \"new normal\". If so, that would be a good checking point for our model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1.2 Description of the data and how it will be used to solve the problem"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We would like to use the city's postal codes to scan for the most trending venues. Each postal code will help to split each city into parts, it is a good base for mapping and scanning for potential target--a good spot for a coffee shop. \n",
    "\n",
    "The postal codes can be obtained over the Internet. Geolocation of those ZIP codes can be sourced over the Geocoder Python module. Then those ZIP code coordinates can be used to obtain trending venues over Foursquare API. All the trending venues will be clustered. For clustering, we will use the DBSCAN clustering algorithm. We will look for clusters with trending Coffee Shop venues. Those clusters will be mapped with the Python Folium module. \n",
    "\t\n",
    "> Python modules:\n",
    "- numpy\n",
    "- pandas\n",
    " - folium\n",
    " - geocoder\n",
    " - foursquare\n",
    " - sklearn\n",
    " - matplotlib\n",
    "\t\n",
    "\n",
    "\t\n",
    "> Postal Codes Sources:\n",
    "- Toronto Postal Codes: https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\n",
    "- Chicago ZIP Codes: https://data.cityofchicago.org/Facilities-Geographic-Boundaries/Chicago-Zip-Code-and-Neighborhood-Map/mapn-ahfc\n",
    "- Houston: https://web.har.com/zipcode'\n",
    "- New York City: https://www.nycbynatives.com/nyc_info/new_york_city_zip_codes.php\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}